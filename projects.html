<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Amin Nasim</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="wrapper">
        <header>
            <nav>
                <a href="index.html#about-me">About</a>
                <a href="projects.html">Projects</a>
                <a href="material/resume.pdf" download="resume.pdf" target="_blank">CV</a>
            </nav>
        </header>
        <div class="container">
            <div class="content center-content">
                <div class="skill-card">
                    <h2>Volume Renderer With GUI </h2>
                    <b>Visualization of 3D data (Python, PyTorch, MatPlotLib, Vectorized Implementation)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/volume-renderer-GUI.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>
                        In this project, I developed a volume renderer from the ground up using Python and PyTorch. Volume rendering is a crucial technique for visualizing and interacting with 3D data (volumes). A transfer function determines the color and opacity of the samples. I designed a GUI for easy testing of my implementation, and I believe the results turned out fantastic.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/Volume-Renderer-From-Scratch-With-GUI" target="_blank">GitHub Link</a></b><br>
                </div>
                <div class="skill-card">
                    <h2>Visulization of MRI 3D Data Based on One Example </h2>
                    <b>Deep Learing (Python, PyTorch, Vectorized Implementation)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/brain-visualization.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>Visualizing volumetric data is a key tool for effective communication, with the transfer function playing a pivotal role in deciding what aspects of the volume to display and how. However, in MRI volumes, the data values can vary significantly due to factors like manufacturer differences and patient-specific details. As a result, a transfer function designed for one volume may not be effective for another. In this project, our TTF method is employed to optimize and visualize brain MRIs based on examples. By providing a reference volume and its transfer function, the method can visualize new, unseen MRI volumes.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/TTF-Brain-Visualization" target="_blank">GitHub Link</a></b><br>
                    <b><a href="https://www.sciencedirect.com/science/article/pii/S0097849324002024" target="_blank">Link to the paper</a></b><br>
                    <b><a href="https://prism.ucalgary.ca/items/6514e9d5-8c7b-44e7-ab2a-9bba84c9767e" target="_blank">Link to the thesis</a></b>
                </div>
                <div class="skill-card">
                    <h2>Automated Transfer Function Generation for Tracking Shock Waves in Volumetric Data</h2>
                    <b>Deep Learing (Python, PyTorch, Vectorized Implementation)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/shock-wave-visulization.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>
                        Visualizing volumetric datasets through volume rendering can be challenging, as each volume in the dataset typically requires a unique transfer function. In one of the applications presented in this work (TTF paper), we visualize 50 time steps of an asteroid blast shock wave in water, where the user provided only a single transfer function. Our method automatically generated the subsequent transfer functions, optimizing them to track the shock wave. Despite the shock wave losing strength and expanding in size over time, our method effectively tracks it across all time steps my modifing pressure (scalar) opacity and gradient opacity functions.</p>

                    <br>
                    <b><a href="#">GitHub Link: To be available soon</a></b><br>
                    <b><a href="https://www.sciencedirect.com/science/article/pii/S0097849324002024" target="_blank">Link to the paper</a></b><br>
                    <b><a href="https://prism.ucalgary.ca/items/6514e9d5-8c7b-44e7-ab2a-9bba84c9767e" target="_blank">Link to the thesis</a></b>
                </div>
                <div class="skill-card">
                    <h2>Mass-Spring System</h2>
                    <b>Simulation & Animation (C++, OpenGL)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/jelly-cube-sim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <video width="600" controls>
                            <source src="media/cloth-sim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <br>
                        <video width="600" controls>
                            <source src="media/cloth-sphere-sim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <video width="600" controls>
                            <source src="media/chain-sim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>

                    </div>
                    <br>
                    <p>In this project, I developed a mass-spring system to simulate various behaviors, including chain, cloth, and jelly cube dynamics. I utilized the semi-implicit Euler method to ensure the simulation remains stable within bounds. To enhance realism, I incorporated air damping and spring damping. For collision handling, I implemented two types: boundary collision, as seen in the jelly cube and cloth on sphere models, and self-collision, to prevent the models from folding and colliding with themselves.</p>
                    <p>The code for this project is <b>not public</b>. To receive the code for this project please send me an email.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/Mass-Spring-Simulation" target="_blank">GitHub Link</a></b>
                </div>
                <div class="skill-card">
                    <h2>Silhouette Rendering</h2>
                    <b>Rendering (C++, OpenGL, GLSL)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/bunny-silhouettes.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>In this project, I implemented Silhouette Rendering, a non-photorealistic rendering technique that produces artistic and visually appealing results. This implementation detects and renders only the edges where one surface is visible while the adjacent surface is hidden, effectively outlining the silhouette of the object.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/Outline-Rendering" target="_blank">GitHub Link</a></b>
                </div>
                <div class="skill-card">
                    <h2>2D Tone Based Mapping</h2>
                    <b>Rendering (C++, OpenGL, GLSL)</b>
                    <div class="video-section">
                        <img src="media/abstract-face.PNG" width="600" height="450">
                        <img src="media/golden-boss.png" width="600" height="450">
                        <video width="600" controls>
                            <source src="media/xtoon-distance1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <video width="600" controls>
                            <source src="media/xtoon-distance2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>In this project, I implemented Attribute-Based Mapping based on the paper "X-Toon: An Extended Toon Shader." This approach utilizes 2D tone mapping (tone texture and tone detail) to achieve effects such as abstraction, backlighting, and near-silhouette enhancement.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/Rendering-Xtoon" target="_blank">GitHub Link</a></b>
                </div>
                <div class="skill-card">
                    <h2>Birds Flocking Simulation (BOID Algorithm)</h2>
                    <b>Simulation & Animation (C++, OpenGL)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/boids.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>In this project, I implemented boids algorithm to simulate birds flocking behavior. The rules applied in this simulation are <b>separation</b> (to avoid vrowding local flockmates), <b>alignment</b> (steer towards the average heading of local flockmates), and <b>cohesion</b> (steer to move towards the average position).</p>
                    <p>The code for this project is <b>not public</b>. To receive the code for this project please send me an email.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/bird-flocking-simulation" target="_blank">GitHub Link</a></b>
                </div>
                <div class="skill-card">
                    <h2>Physically-Based Roller Coaster Simulation</h2>
                    <b>Simulation & Animation (C++, OpenGL)</b>
                    <div class="video-section">
                        <video width="600" controls>
                            <source src="media/roller-coaster-sim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <p>This project involves a fascinating physically-based roller coaster simulation that I developed. The simulation operates on the principle of energy conservation, except during the lifting phase where a motor is assumed to lift the carts to the top. Beyond that point, the sum of potential and kinetic energy remains constant. The roller coaster track is designed using Catmull-Rom splines, and the tracks automatically adjust their banking to keep the carts securely on the track while counteracting centrifugal force.</p>
                    <p>The code for this project is <b>not public</b>. To receive the code for this project please send me an email.</p>
                    <br>
                    <b><a href="https://github.com/amin1nasim/Roller-Coaster-Simulation" target="_blank">GitHub Link</a></b>
                </div>
            </div>
        </div>
    </div>
    <script src="script.js"></script>
</body>
</html>
